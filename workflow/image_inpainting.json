{
  "1": {
    "inputs": {
      "image": "000012 (3).png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3": {
    "inputs": {
      "image": "000007_mask.png",
      "channel": "red",
      "upload": "image"
    },
    "class_type": "LoadImageMask",
    "_meta": {
      "title": "Load Image (as Mask)"
    }
  },
  "5": {
    "inputs": {
      "max_length": 768,
      "image": [
        "62",
        0
      ]
    },
    "class_type": "ImagePreprocess",
    "_meta": {
      "title": "ImagePreprocess Inpaint"
    }
  },
  "8": {
    "inputs": {
      "max_length": 768,
      "image": [
        "9",
        0
      ]
    },
    "class_type": "ImagePreprocess",
    "_meta": {
      "title": "ImagePreprocess Inpaint"
    }
  },
  "9": {
    "inputs": {
      "mask": [
        "62",
        1
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "10": {
    "inputs": {
      "channel": "red",
      "image": [
        "8",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "12": {
    "inputs": {
      "seed": 223358464508711,
      "inpaint_model": [
        "13",
        0
      ],
      "image": [
        "1",
        0
      ],
      "mask": [
        "3",
        0
      ]
    },
    "class_type": "INPAINT_InpaintingWithModel",
    "_meta": {
      "title": "Inpainting (using Model)"
    }
  },
  "13": {
    "inputs": {
      "model_name": "big-lama.pt"
    },
    "class_type": "INPAINT_LoadModel",
    "_meta": {
      "title": "Load Model Inpaint"
    }
  },
  "14": {
    "inputs": {
      "resolution": 512,
      "image": [
        "12",
        0
      ]
    },
    "class_type": "Zoe-DepthMapPreprocessor",
    "_meta": {
      "title": "Zoe Depth Map"
    }
  },
  "15": {
    "inputs": {
      "grow_mask_by": 20,
      "pixels": [
        "5",
        0
      ],
      "vae": [
        "17",
        0
      ],
      "mask": [
        "10",
        0
      ]
    },
    "class_type": "INPAINT_VAEEncode",
    "_meta": {
      "title": "VAE Encode Inpaint"
    }
  },
  "16": {
    "inputs": {
      "samples": [
        "23",
        0
      ],
      "vae": [
        "17",
        0
      ],
      "pixels": [
        "5",
        0
      ]
    },
    "class_type": "INPAINT_VAEDecode",
    "_meta": {
      "title": "VAE Decode Inpaint"
    }
  },
  "17": {
    "inputs": {
      "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "18": {
    "inputs": {
      "text": "background, empty scene",
      "clip": [
        "44",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "19": {
    "inputs": {
      "text": "man, woman, (((human))), blur, text, watermark, nsfw, confusion",
      "clip": [
        "44",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "20": {
    "inputs": {
      "ckpt_name": "stable-diffusion-inpainting/sd-v1-5-inpainting.ckpt"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "21": {
    "inputs": {
      "strength": 0.8,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "18",
        0
      ],
      "negative": [
        "19",
        0
      ],
      "control_net": [
        "22",
        0
      ],
      "image": [
        "69",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "22": {
    "inputs": {
      "control_net_name": "control_v11f1p_sd15_depth.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "23": {
    "inputs": {
      "seed": 835629437992385,
      "steps": 4,
      "cfg": 3,
      "sampler_name": "dpmpp_sde_gpu",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "44",
        0
      ],
      "positive": [
        "21",
        0
      ],
      "negative": [
        "21",
        1
      ],
      "latent_image": [
        "15",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "24": {
    "inputs": {
      "factor": 1,
      "image": [
        "16",
        0
      ],
      "reference": [
        "5",
        0
      ],
      "mask": [
        "10",
        0
      ]
    },
    "class_type": "INPAINT_ColorCorrection",
    "_meta": {
      "title": "ColorCorrection Inpaint"
    }
  },
  "25": {
    "inputs": {
      "max_length": 768,
      "input_image": [
        "62",
        0
      ],
      "output_image": [
        "24",
        0
      ]
    },
    "class_type": "ImagePostprocess",
    "_meta": {
      "title": "ImagePostprocess Inpaint"
    }
  },
  "26": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": false,
      "destination": [
        "62",
        0
      ],
      "source": [
        "25",
        0
      ],
      "mask": [
        "28",
        0
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  },
  "27": {
    "inputs": {
      "dilation": 15,
      "mask": [
        "10",
        0
      ]
    },
    "class_type": "ImpactDilateMask",
    "_meta": {
      "title": "Dilate Mask"
    }
  },
  "28": {
    "inputs": {
      "kernel_size": 10,
      "sigma": 10,
      "mask": [
        "27",
        0
      ]
    },
    "class_type": "ImpactGaussianBlurMask",
    "_meta": {
      "title": "Gaussian Blur Mask"
    }
  },
  "44": {
    "inputs": {
      "lora_name": "pytorch_lora_weights.safetensors",
      "strength_model": 0.8,
      "strength_clip": 0.8,
      "model": [
        "20",
        0
      ],
      "clip": [
        "20",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "62": {
    "inputs": {
      "pad_ratio": 0.2,
      "image": [
        "1",
        0
      ],
      "mask": [
        "3",
        0
      ]
    },
    "class_type": "INPAINT_CropImage",
    "_meta": {
      "title": "Crop Image Inpaint"
    }
  },
  "63": {
    "inputs": {
      "image": [
        "1",
        0
      ],
      "crop_image": [
        "26",
        0
      ],
      "rect": [
        "62",
        2
      ]
    },
    "class_type": "INPAINT_PasteBackCropImage",
    "_meta": {
      "title": "Paste Back Crop Image Inpaint"
    }
  },
  "69": {
    "inputs": {
      "original_image": [
        "1",
        0
      ],
      "image": [
        "14",
        0
      ],
      "rect": [
        "62",
        2
      ]
    },
    "class_type": "CropImageByRect",
    "_meta": {
      "title": "Crop Image by Rect"
    }
  },
  "74": {
    "inputs": {
      "images": [
        "63",
        0
      ]
    },
    "class_type": "SaveImageWebsocket",
    "_meta": {
      "title": "SaveImageWebsocket"
    }
  }
}